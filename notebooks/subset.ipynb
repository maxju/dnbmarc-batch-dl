{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset of dnb records (10000 entries)\n",
    "\n",
    "import psycopg2\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Umgebungsvariablen laden\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def connect_to_db() -> psycopg2.extensions.connection:\n",
    "    \"\"\"Datenbankverbindung herstellen\"\"\"\n",
    "    return psycopg2.connect(\n",
    "        host=os.getenv(\"DB_HOST\"),\n",
    "        port=os.getenv(\"DB_PORT\"),\n",
    "        database=os.getenv(\"DB_NAME\"),\n",
    "        user=os.getenv(\"DB_USER\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_base_conditions() -> str:\n",
    "    \"\"\"Basisbedingungen für die Datenbankabfrage\"\"\"\n",
    "    return \"\"\"\n",
    "        num_pages <= 200 \n",
    "        AND abstract_num IS NOT NULL \n",
    "        AND abstract_num != '0'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def get_category_counts(cur: psycopg2.extensions.cursor) -> Dict[str, int]:\n",
    "    \"\"\"Ermittelt die Anzahl der Einträge pro DDC-Kategorie\"\"\"\n",
    "    base_conditions = get_base_conditions()\n",
    "    category_counts = {}\n",
    "\n",
    "    for ddc in range(10):\n",
    "        ddc_str = str(ddc)\n",
    "        cur.execute(\n",
    "            f\"\"\"\n",
    "            SELECT COUNT(*)\n",
    "            FROM dnb_records\n",
    "            WHERE {base_conditions}\n",
    "              AND SUBSTRING(ddc FROM 1 FOR 1) = %s\n",
    "        \"\"\",\n",
    "            (ddc_str,),\n",
    "        )\n",
    "        category_counts[ddc_str] = cur.fetchone()[0]\n",
    "\n",
    "    return category_counts\n",
    "\n",
    "\n",
    "def create_balanced_subset(category_counts: Dict[str, int], total_needed: int) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Erstellt ein ausgewogenes Subset der Daten durch rotierende Auswahl.\n",
    "    Verteilt die Einträge gleichmäßig auf alle Kategorien, die noch Einträge haben.\n",
    "    \"\"\"\n",
    "    entries_needed = {ddc: 0 for ddc in category_counts.keys()}\n",
    "    remaining_entries = {ddc: count for ddc, count in category_counts.items()}\n",
    "    entries_to_allocate = total_needed\n",
    "\n",
    "    while entries_to_allocate > 0:\n",
    "        # Nur Kategorien berücksichtigen, die noch Einträge haben\n",
    "        available_categories = [ddc for ddc, count in remaining_entries.items() if count > 0]\n",
    "\n",
    "        if not available_categories:\n",
    "            break\n",
    "\n",
    "        # Berechne, wie viele Einträge pro Kategorie in dieser Runde verteilt werden\n",
    "        entries_per_category = max(1, entries_to_allocate // len(available_categories))\n",
    "\n",
    "        for ddc in available_categories:\n",
    "            # Nimm den kleineren Wert: verfügbare Einträge oder zu verteilende Einträge\n",
    "            entries_to_take = min(remaining_entries[ddc], entries_per_category, entries_to_allocate)\n",
    "\n",
    "            entries_needed[ddc] += entries_to_take\n",
    "            remaining_entries[ddc] -= entries_to_take\n",
    "            entries_to_allocate -= entries_to_take\n",
    "\n",
    "            if entries_to_allocate <= 0:\n",
    "                break\n",
    "\n",
    "    return entries_needed\n",
    "\n",
    "\n",
    "def create_subset_table(cur: psycopg2.extensions.cursor, entries_needed: Dict[str, int]) -> None:\n",
    "    \"\"\"Erstellt eine neue Tabelle für das Subset\"\"\"\n",
    "    # First create an index on the main table if it doesn't exist\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS idx_dnb_records_ddc \n",
    "        ON dnb_records(ddc, num_pages, abstract_num);\n",
    "    \"\"\")\n",
    "    \n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        DROP TABLE IF EXISTS dnb_records_subset;\n",
    "        CREATE TABLE dnb_records_subset AS\n",
    "        WITH ranked_records AS (\n",
    "            SELECT *,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY SUBSTRING(ddc FROM 1 FOR 1)\n",
    "                    ORDER BY RANDOM()\n",
    "                ) as row_num\n",
    "            FROM dnb_records\n",
    "            WHERE num_pages <= 200 \n",
    "                AND abstract_num IS NOT NULL \n",
    "                AND abstract_num != '0'\n",
    "        )\n",
    "        SELECT * FROM ranked_records r\n",
    "        WHERE row_num <= (\n",
    "            SELECT count::integer\n",
    "            FROM jsonb_each_text(%s) as t(ddc, count)\n",
    "            WHERE t.ddc = SUBSTRING(r.ddc FROM 1 FOR 1)\n",
    "        );\n",
    "    \"\"\",\n",
    "        (json.dumps(entries_needed),),\n",
    "    )\n",
    "\n",
    "\n",
    "def create_subset_indices(cur: psycopg2.extensions.cursor) -> None:\n",
    "    \"\"\"Erstellt Indizes für die Subset-Tabelle\"\"\"\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        CREATE INDEX idx_subset_ddc ON dnb_records_subset(ddc);\n",
    "        CREATE INDEX idx_subset_id ON dnb_records_subset(id);\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def verify_subset(cur: psycopg2.extensions.cursor, entries_needed: Dict[str, int]) -> None:\n",
    "    \"\"\"Überprüft, ob das Subset korrekt erstellt wurde\"\"\"\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        SELECT SUBSTRING(ddc FROM 1 FOR 1) as ddc_category, COUNT(*) as count\n",
    "        FROM dnb_records_subset\n",
    "        GROUP BY ddc_category\n",
    "        ORDER BY ddc_category;\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    results = cur.fetchall()\n",
    "    print(\"\\nTatsächliche Verteilung im Subset:\")\n",
    "    for ddc_category, count in results:\n",
    "        expected = entries_needed.get(ddc_category, 0)\n",
    "        print(f\"DDC {ddc_category}: {count} Einträge (Erwartet: {expected})\")\n",
    "\n",
    "def drop_subset_table(conn: psycopg2.extensions.connection) -> None:\n",
    "    \"\"\"Drops the subset table efficiently\"\"\"\n",
    "    with conn.cursor() as cursor:\n",
    "        # Drop the indices first for faster drop\n",
    "        cursor.execute(\"\"\"\n",
    "            DROP INDEX IF EXISTS idx_subset_ddc;\n",
    "            DROP INDEX IF EXISTS idx_subset_id;\n",
    "            DROP TABLE IF EXISTS dnb_records_subset;\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "def force_drop_table(conn: psycopg2.extensions.connection) -> None:\n",
    "    \"\"\"Force drops the table by first terminating conflicting connections\"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        # Terminate any other connections to the table\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT pg_terminate_backend(pid)\n",
    "            FROM pg_stat_activity\n",
    "            WHERE pid != pg_backend_pid()\n",
    "              AND query LIKE '%dnb_records_subset%';\n",
    "        \"\"\")\n",
    "        \n",
    "        # Drop the indices and table\n",
    "        cur.execute(\"\"\"\n",
    "            DROP INDEX IF EXISTS idx_subset_ddc;\n",
    "            DROP INDEX IF EXISTS idx_subset_id;\n",
    "            DROP TABLE IF EXISTS dnb_records_subset;\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "def main():\n",
    "    # Verbindung zur Datenbank herstellen\n",
    "    conn = connect_to_db()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Gesamtzahl der gefilterten Einträge ermitteln\n",
    "        cur.execute(\n",
    "            f\"\"\"\n",
    "            SELECT COUNT(*) \n",
    "            FROM dnb_records \n",
    "            WHERE {get_base_conditions()}\n",
    "        \"\"\"\n",
    "        )\n",
    "        total_filtered_records = cur.fetchone()[0]\n",
    "        print(f\"Gesamtzahl der gefilterten Einträge: {total_filtered_records}\")\n",
    "\n",
    "        # Anzahl der Einträge pro Kategorie ermitteln\n",
    "        category_counts = get_category_counts(cur)\n",
    "        print(\"\\nAnzahl der Einträge pro DDC-Kategorie:\")\n",
    "        for ddc, count in category_counts.items():\n",
    "            print(f\"DDC {ddc}: {count} Einträge\")\n",
    "\n",
    "        # Subset erstellen\n",
    "        total_needed = 10000\n",
    "        entries_needed = create_balanced_subset(category_counts, total_needed)\n",
    "\n",
    "        print(\"\\nBerechnete Anzahl der Einträge pro DDC-Kategorie für das Subset:\")\n",
    "        for ddc, count in entries_needed.items():\n",
    "            print(f\"DDC {ddc}: {count} Einträge\")\n",
    "\n",
    "\n",
    "        # Drop the table if it exists\n",
    "        print(\"\\nDropping subset table if it exists...\")\n",
    "        force_drop_table(conn)\n",
    "\n",
    "        # Subset in Datenbank speichern\n",
    "        print(\"\\nErstelle Subset-Tabelle...\")\n",
    "        create_subset_table(cur, entries_needed)\n",
    "\n",
    "        print(\"Erstelle Indizes...\")\n",
    "        create_subset_indices(cur)\n",
    "\n",
    "        print(\"Überprüfe Subset...\")\n",
    "        verify_subset(cur, entries_needed)\n",
    "\n",
    "        # Änderungen committen\n",
    "        conn.commit()\n",
    "\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset and print schema and example entries\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Umgebungsvariablen laden\n",
    "load_dotenv()\n",
    "\n",
    "def connect_to_db() -> psycopg2.extensions.connection:\n",
    "    \"\"\"Datenbankverbindung herstellen\"\"\"\n",
    "    return psycopg2.connect(\n",
    "        host=os.getenv(\"DB_HOST\"),\n",
    "        port=os.getenv(\"DB_PORT\"),\n",
    "        database=os.getenv(\"DB_NAME\"),\n",
    "        user=os.getenv(\"DB_USER\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\"),\n",
    "    )\n",
    "\n",
    "# Verbindung zur Subset-Datenbank herstellen\n",
    "subset_conn = connect_to_db()\n",
    "subset_cur = subset_conn.cursor()\n",
    "\n",
    "# Anzahl der Einträge in der Subset-Tabelle zählen\n",
    "subset_cur.execute(\"SELECT COUNT(*) FROM dnb_records_subset;\")\n",
    "total_subset_entries = subset_cur.fetchone()[0]\n",
    "print(f\"Gesamtzahl der Einträge in der Subset-Tabelle: {total_subset_entries}\")\n",
    "\n",
    "# Schema der Tabelle anzeigen\n",
    "subset_cur.execute(\n",
    "    \"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = 'dnb_records_subset'\n",
    "    ORDER BY ordinal_position;\n",
    "\"\"\"\n",
    ")\n",
    "print(\"Schema der Subset-Tabelle:\")\n",
    "for column in subset_cur.fetchall():\n",
    "    print(f\"{column[0]}: {column[1]}\")\n",
    "\n",
    "print(\"\\n5 Beispieleinträge:\")\n",
    "subset_cur.execute(\n",
    "    \"\"\"\n",
    "    SELECT * FROM dnb_records_subset\n",
    "    ORDER BY RANDOM() \n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    ")\n",
    "for row in subset_cur.fetchall():\n",
    "    print(\"\\n---\")\n",
    "    for i, column in enumerate(subset_cur.description):\n",
    "        print(f\"{column.name}: {row[i]}\")\n",
    "\n",
    "# Ressourcen freigeben\n",
    "subset_cur.close()\n",
    "subset_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connect to database\n",
    "conn = connect_to_db()\n",
    "\n",
    "# Query to get the data\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    SUBSTRING(ddc FROM 1 FOR 1) as ddc_category,\n",
    "    year,\n",
    "    COUNT(*) as count\n",
    "FROM dnb_records_subset\n",
    "WHERE year IS NOT NULL\n",
    "GROUP BY SUBSTRING(ddc FROM 1 FOR 1), year\n",
    "ORDER BY year, ddc_category;\n",
    "\"\"\"\n",
    "\n",
    "# Read data into DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create stacked bar plot\n",
    "plot = sns.barplot(data=df, x=\"year\", y=\"count\", hue=\"ddc_category\", palette=\"husl\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Publications per Year by DDC Category\", pad=20)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Publications\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add legend with DDC category descriptions\n",
    "ddc_descriptions = {\n",
    "    \"0\": \"Computer Science, Information & General Works\",\n",
    "    \"1\": \"Philosophy & Psychology\",\n",
    "    \"2\": \"Religion\",\n",
    "    \"3\": \"Social Sciences\",\n",
    "    \"4\": \"Language\",\n",
    "    \"5\": \"Science\",\n",
    "    \"6\": \"Technology\",\n",
    "    \"7\": \"Arts & Recreation\",\n",
    "    \"8\": \"Literature\",\n",
    "    \"9\": \"History & Geography\",\n",
    "}\n",
    "\n",
    "# Update legend labels\n",
    "handles = plot.get_legend_handles_labels()[0]\n",
    "labels = [f\"{cat} - {ddc_descriptions[cat]}\" for cat in plot.get_legend_handles_labels()[1]]\n",
    "plt.legend(handles, labels, title=\"DDC Categories\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Close connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db() -> psycopg2.extensions.connection:\n",
    "    \"\"\"Datenbankverbindung herstellen\"\"\"\n",
    "    return psycopg2.connect(\n",
    "        host=os.getenv(\"DB_HOST\"),\n",
    "        port=os.getenv(\"DB_PORT\"),\n",
    "        database=os.getenv(\"DB_NAME\"),\n",
    "        user=os.getenv(\"DB_USER\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\"),\n",
    "    )\n",
    "\n",
    "conn = connect_to_db()\n",
    "\n",
    "# Drop the table if it exists\n",
    "drop_table_query = \"DROP TABLE IF EXISTS dnb_records_subset\"\n",
    "\n",
    "# Execute the query\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(drop_table_query)\n",
    "    conn.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
