{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def connect_to_db() -> psycopg2.extensions.connection:\n",
    "    return psycopg2.connect(\n",
    "        host=os.getenv(\"DB_HOST\"),\n",
    "        port=os.getenv(\"DB_PORT\"),\n",
    "        database=os.getenv(\"DB_NAME\"),\n",
    "        user=os.getenv(\"DB_USER\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\"),\n",
    "    )\n",
    "\n",
    "def read_gnd_mappings(file_path: str) -> tuple:\n",
    "    \"\"\"Read GND mappings from CSV file and return unique values\"\"\"\n",
    "    print(\"Reading CSV file...\")\n",
    "    # Read CSV and immediately drop duplicates\n",
    "    df = pd.read_csv(file_path).drop_duplicates()\n",
    "    \n",
    "    # Get unique doc_idns\n",
    "    doc_idns = df['doc_idn'].unique().tolist()\n",
    "    \n",
    "    # Get unique GND entities\n",
    "    gnd_entities = df[['gnd_idn', 'gnd_label']].drop_duplicates().values.tolist()\n",
    "    \n",
    "    # Get mappings (now without duplicates)\n",
    "    mappings = df[['doc_idn', 'gnd_idn']].values.tolist()\n",
    "    \n",
    "    print(f\"Found {len(doc_idns)} unique documents\")\n",
    "    print(f\"Found {len(gnd_entities)} unique GND entities\")\n",
    "    print(f\"Found {len(mappings)} total mappings (after removing duplicates)\")\n",
    "    \n",
    "    return doc_idns, gnd_entities, mappings\n",
    "\n",
    "def create_gnd_tables(cur: psycopg2.extensions.cursor) -> None:\n",
    "    \"\"\"Create GND tables with proper constraints\"\"\"\n",
    "    print(\"Dropping existing tables...\")\n",
    "    cur.execute(\"\"\"\n",
    "        DROP TABLE IF EXISTS dnb_gnd_mappings;\n",
    "        DROP TABLE IF EXISTS dnb_gnd_entities;\n",
    "        DROP TABLE IF EXISTS dnb_records_gnd;\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"Creating new tables...\")\n",
    "    # Create records subset table\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE dnb_records_gnd AS \n",
    "        SELECT * FROM dnb_records WHERE FALSE;\n",
    "        ALTER TABLE dnb_records_gnd ADD PRIMARY KEY (id);\n",
    "        CREATE INDEX idx_records_gnd_idn ON dnb_records_gnd(idn);\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create GND entities table\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE dnb_gnd_entities (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            gnd_idn VARCHAR NOT NULL UNIQUE,\n",
    "            gnd_label TEXT NOT NULL\n",
    "        );\n",
    "        CREATE INDEX idx_gnd_entities_idn ON dnb_gnd_entities(gnd_idn);\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create mappings table\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE dnb_gnd_mappings (\n",
    "            record_id INTEGER REFERENCES dnb_records_gnd(id),\n",
    "            gnd_id INTEGER REFERENCES dnb_gnd_entities(id),\n",
    "            PRIMARY KEY (record_id, gnd_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "def populate_tables(cur: psycopg2.extensions.cursor, doc_idns: list, gnd_entities: list, mappings: list) -> None:\n",
    "    \"\"\"Populate all tables efficiently using batch operations\"\"\"\n",
    "    # Check if we need to populate GND entities\n",
    "    cur.execute(\"SELECT COUNT(*) FROM dnb_gnd_entities\")\n",
    "    current_count = cur.fetchone()[0]\n",
    "    \n",
    "    if current_count != len(gnd_entities):\n",
    "        print(\"Inserting GND entities...\")\n",
    "        # Batch insert GND entities in chunks\n",
    "        chunk_size = 1000\n",
    "        for i in range(0, len(gnd_entities), chunk_size):\n",
    "            chunk = gnd_entities[i:i + chunk_size]\n",
    "            cur.executemany(\"\"\"\n",
    "                INSERT INTO dnb_gnd_entities (gnd_idn, gnd_label) \n",
    "                VALUES (%s, %s) \n",
    "                ON CONFLICT (gnd_idn) DO NOTHING\n",
    "            \"\"\", chunk)\n",
    "            print(f\"Processed {min(i + chunk_size, len(gnd_entities))}/{len(gnd_entities)} entities\")\n",
    "            # Commit after each chunk to save progress\n",
    "            cur.connection.commit()\n",
    "    else:\n",
    "        print(\"GND entities already populated, skipping...\")\n",
    "\n",
    "    print(\"Copying records...\")\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO dnb_records_gnd \n",
    "        SELECT * FROM dnb_records \n",
    "        WHERE idn = ANY(%s)\n",
    "        ON CONFLICT DO NOTHING\n",
    "    \"\"\", (doc_idns,))\n",
    "    \n",
    "    print(\"Creating mappings...\")\n",
    "    # First create a temporary table for the mappings\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TEMP TABLE temp_mappings (\n",
    "            doc_idn VARCHAR,\n",
    "            gnd_idn VARCHAR\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Insert into temp table\n",
    "    cur.executemany(\"\"\"\n",
    "        INSERT INTO temp_mappings (doc_idn, gnd_idn)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\", mappings)\n",
    "    \n",
    "    # Insert from temp table, eliminating duplicates\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO dnb_gnd_mappings (record_id, gnd_id)\n",
    "        SELECT DISTINCT r.id, e.id\n",
    "        FROM temp_mappings m\n",
    "        JOIN dnb_records_gnd r ON r.idn = m.doc_idn::varchar\n",
    "        JOIN dnb_gnd_entities e ON e.gnd_idn = m.gnd_idn::varchar\n",
    "        ON CONFLICT DO NOTHING\n",
    "    \"\"\")\n",
    "    \n",
    "    # Clean up\n",
    "    cur.execute(\"DROP TABLE temp_mappings\")\n",
    "\n",
    "def main():\n",
    "    print(\"Starting process...\")\n",
    "    # Read GND mappings\n",
    "    doc_idns, gnd_entities, mappings = read_gnd_mappings(\"../data/ger_open_access_with_gnd.csv\")\n",
    "    \n",
    "    # Connect to database\n",
    "    print(\"Connecting to database...\")\n",
    "    conn = connect_to_db()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        create_gnd_tables(cur)\n",
    "        populate_tables(cur, doc_idns, gnd_entities, mappings)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nFinal Statistics:\")\n",
    "        cur.execute(\"SELECT COUNT(*) FROM dnb_records_gnd\")\n",
    "        print(f\"Records in subset: {cur.fetchone()[0]}\")\n",
    "        \n",
    "        cur.execute(\"SELECT COUNT(*) FROM dnb_gnd_entities\")\n",
    "        print(f\"GND entities: {cur.fetchone()[0]}\")\n",
    "        \n",
    "        cur.execute(\"SELECT COUNT(*) FROM dnb_gnd_mappings\")\n",
    "        print(f\"Total mappings: {cur.fetchone()[0]}\")\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"\\nDone!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def connect_to_db() -> psycopg2.extensions.connection:\n",
    "    return psycopg2.connect(\n",
    "        host=os.getenv(\"DB_HOST\"),\n",
    "        port=os.getenv(\"DB_PORT\"),\n",
    "        database=os.getenv(\"DB_NAME\"),\n",
    "        user=os.getenv(\"DB_USER\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\"),\n",
    "    )\n",
    "\n",
    "# Connect to database and get statistics for GND tables\n",
    "conn = connect_to_db()\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Get basic statistics\n",
    "cur.execute(\"\"\"\n",
    "    SELECT \n",
    "        (SELECT COUNT(*) FROM dnb_records_gnd) as total_records,\n",
    "        (SELECT COUNT(*) FROM dnb_gnd_entities) as total_gnd_entities,\n",
    "        (SELECT COUNT(*) FROM dnb_gnd_mappings) as total_mappings,\n",
    "        (SELECT AVG(mapping_count) \n",
    "         FROM (\n",
    "             SELECT COUNT(*) as mapping_count \n",
    "             FROM dnb_gnd_mappings \n",
    "             GROUP BY record_id\n",
    "         ) t) as avg_mappings_per_record,\n",
    "        (SELECT MAX(mapping_count) \n",
    "         FROM (\n",
    "             SELECT COUNT(*) as mapping_count \n",
    "             FROM dnb_gnd_mappings \n",
    "             GROUP BY record_id\n",
    "         ) t) as max_mappings_per_record\n",
    "\"\"\")\n",
    "\n",
    "stats = cur.fetchone()\n",
    "print(\"Statistics:\")\n",
    "print(f\"Total records with GND: {stats[0]}\")\n",
    "print(f\"Total GND entities: {stats[1]}\")\n",
    "print(f\"Total GND mappings: {stats[2]}\")\n",
    "print(f\"Average GND entries per document: {stats[3]:.2f}\")\n",
    "print(f\"Maximum GND entries per document: {stats[4]}\")\n",
    "\n",
    "# Get a random record with its GND keywords\n",
    "print(\"\\nRandom record with GND keywords:\")\n",
    "cur.execute(\"\"\"\n",
    "    WITH random_record AS (\n",
    "        SELECT id, idn, title \n",
    "        FROM dnb_records_gnd \n",
    "        ORDER BY RANDOM() \n",
    "        LIMIT 1\n",
    "    )\n",
    "    SELECT \n",
    "        r.idn,\n",
    "        r.title,\n",
    "        STRING_AGG(e.gnd_label, ' | ' ORDER BY e.gnd_label) as gnd_keywords,\n",
    "        COUNT(*) as keyword_count\n",
    "    FROM random_record r\n",
    "    JOIN dnb_gnd_mappings m ON m.record_id = r.id\n",
    "    JOIN dnb_gnd_entities e ON e.id = m.gnd_id\n",
    "    GROUP BY r.idn, r.title\n",
    "\"\"\")\n",
    "\n",
    "record = cur.fetchone()\n",
    "print(f\"\\nIDN: {record[0]}\")\n",
    "print(f\"Title: {record[1]}\")\n",
    "print(f\"Number of GND keywords: {record[3]}\")\n",
    "print(f\"GND keywords: {record[2]}\")\n",
    "\n",
    "# Distribution of GND keywords per document\n",
    "print(\"\\nDistribution of GND keywords per document:\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT \n",
    "        keyword_count,\n",
    "        COUNT(*) as document_count,\n",
    "        ROUND(COUNT(*)::numeric / SUM(COUNT(*)) OVER () * 100, 2) as percentage\n",
    "    FROM (\n",
    "        SELECT record_id, COUNT(*) as keyword_count\n",
    "        FROM dnb_gnd_mappings\n",
    "        GROUP BY record_id\n",
    "    ) t\n",
    "    GROUP BY keyword_count\n",
    "    ORDER BY keyword_count\n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTop 5 most common keyword counts:\")\n",
    "print(\"Keywords | Documents | Percentage\")\n",
    "print(\"-\" * 40)\n",
    "for row in cur.fetchall():\n",
    "    print(f\"{row[0]:8d} | {row[1]:9d} | {row[2]:8.2f}%\")\n",
    "\n",
    "# Most common GND keywords\n",
    "print(\"\\nTop 10 most common GND keywords:\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT \n",
    "        e.gnd_label,\n",
    "        COUNT(*) as usage_count,\n",
    "        ROUND(COUNT(*)::numeric / (SELECT COUNT(*) FROM dnb_gnd_mappings) * 100, 2) as percentage\n",
    "    FROM dnb_gnd_mappings m\n",
    "    JOIN dnb_gnd_entities e ON e.id = m.gnd_id\n",
    "    GROUP BY e.gnd_label\n",
    "    ORDER BY usage_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nKeyword | Usage Count | Percentage\")\n",
    "print(\"-\" * 50)\n",
    "for row in cur.fetchall():\n",
    "    print(f\"{row[0]:<30} | {row[1]:11d} | {row[2]:8.2f}%\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
